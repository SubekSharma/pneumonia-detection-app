{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Hh3o8DAopllp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b376366-bd66-40a8-9d93-53bebe1f4e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/pneumonia-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cLbcBa-nw58",
        "outputId": "0eafaf32-3459-4090-fc97-6b8eb6258457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/pneumonia-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16, DenseNet169\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import cv2"
      ],
      "metadata": {
        "id": "4aMMsC5o830D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Global variables \"\"\"\n",
        "h = 224\n",
        "w = 224\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "\"\"\"Directory to store files\"\"\"\n",
        "create_dir('files')\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "batch_size = 16\n",
        "lr = 1e-4\n",
        "num_epochs = 50\n",
        "model_path = os.path.join(\"files\", \"model.h5\")\n",
        "csv_path = os.path.join(\"files\", \"log.csv\")"
      ],
      "metadata": {
        "id": "gBBV2W4SDjDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = '/content/drive/MyDrive/pneumonia-dataset/train'\n",
        "test_directory = '/content/drive/MyDrive/pneumonia-dataset/test'\n",
        "validation_directory = '/content/drive/MyDrive/pneumonia-dataset/val'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   rotation_range=10,\n",
        "                                   width_shift_range=0.1,\n",
        "                                   height_shift_range=0.1,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_directory,\n",
        "    target_size=(h, w),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_directory,\n",
        "    target_size=(h, w),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_directory,\n",
        "    target_size=(h, w),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=(h, w, 3))\n",
        "base_model.trainable= False\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(layers.GlobalAveragePooling2D())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-8, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=False),\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaCvRzEmAsSD",
        "outputId": "d1e8f11f-3bf1-47e5-d12b-79a9b4214c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n",
            "Found 400 images belonging to 2 classes.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet169 (Functional)    (None, 7, 7, 1664)        12642880  \n",
            "                                                                 \n",
            " global_average_pooling2d_2  (None, 1664)              0         \n",
            "  (GlobalAveragePooling2D)                                       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               426240    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13069377 (49.86 MB)\n",
            "Trainable params: 426497 (1.63 MB)\n",
            "Non-trainable params: 12642880 (48.23 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                    epochs=50,\n",
        "                    validation_data=validation_generator,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "_iMlhSRp3itz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e8da1e-ccde-41c9-bfa6-1b350a344e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.4089 - accuracy: 0.8075\n",
            "Epoch 1: val_loss improved from inf to 0.33919, saving model to files/model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 536s 4s/step - loss: 0.4089 - accuracy: 0.8075 - val_loss: 0.3392 - val_accuracy: 0.8525 - lr: 1.0000e-04\n",
            "Epoch 2/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.8950\n",
            "Epoch 2: val_loss improved from 0.33919 to 0.32056, saving model to files/model.h5\n",
            "125/125 [==============================] - 73s 588ms/step - loss: 0.2601 - accuracy: 0.8950 - val_loss: 0.3206 - val_accuracy: 0.8775 - lr: 1.0000e-04\n",
            "Epoch 3/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.9055\n",
            "Epoch 3: val_loss did not improve from 0.32056\n",
            "125/125 [==============================] - 70s 554ms/step - loss: 0.2352 - accuracy: 0.9055 - val_loss: 0.3223 - val_accuracy: 0.8650 - lr: 1.0000e-04\n",
            "Epoch 4/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.9205\n",
            "Epoch 4: val_loss improved from 0.32056 to 0.30817, saving model to files/model.h5\n",
            "125/125 [==============================] - 72s 575ms/step - loss: 0.2245 - accuracy: 0.9205 - val_loss: 0.3082 - val_accuracy: 0.8700 - lr: 1.0000e-04\n",
            "Epoch 5/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9265\n",
            "Epoch 5: val_loss did not improve from 0.30817\n",
            "125/125 [==============================] - 69s 551ms/step - loss: 0.1968 - accuracy: 0.9265 - val_loss: 0.3087 - val_accuracy: 0.8950 - lr: 1.0000e-04\n",
            "Epoch 6/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.9315\n",
            "Epoch 6: val_loss did not improve from 0.30817\n",
            "125/125 [==============================] - 68s 542ms/step - loss: 0.1836 - accuracy: 0.9315 - val_loss: 0.3082 - val_accuracy: 0.8950 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9285\n",
            "Epoch 7: val_loss improved from 0.30817 to 0.30794, saving model to files/model.h5\n",
            "125/125 [==============================] - 75s 600ms/step - loss: 0.1755 - accuracy: 0.9285 - val_loss: 0.3079 - val_accuracy: 0.8875 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1905 - accuracy: 0.9345\n",
            "Epoch 8: val_loss improved from 0.30794 to 0.30155, saving model to files/model.h5\n",
            "125/125 [==============================] - 70s 558ms/step - loss: 0.1905 - accuracy: 0.9345 - val_loss: 0.3015 - val_accuracy: 0.8950 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9455\n",
            "Epoch 9: val_loss did not improve from 0.30155\n",
            "125/125 [==============================] - 74s 589ms/step - loss: 0.1705 - accuracy: 0.9455 - val_loss: 0.3138 - val_accuracy: 0.8675 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1722 - accuracy: 0.9390\n",
            "Epoch 10: val_loss did not improve from 0.30155\n",
            "125/125 [==============================] - 66s 532ms/step - loss: 0.1722 - accuracy: 0.9390 - val_loss: 0.3070 - val_accuracy: 0.8875 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9395\n",
            "Epoch 11: val_loss improved from 0.30155 to 0.30152, saving model to files/model.h5\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "125/125 [==============================] - 72s 576ms/step - loss: 0.1629 - accuracy: 0.9395 - val_loss: 0.3015 - val_accuracy: 0.8950 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.9445\n",
            "Epoch 12: val_loss improved from 0.30152 to 0.29922, saving model to files/model.h5\n",
            "125/125 [==============================] - 68s 539ms/step - loss: 0.1500 - accuracy: 0.9445 - val_loss: 0.2992 - val_accuracy: 0.8925 - lr: 1.0000e-05\n",
            "Epoch 13/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1478 - accuracy: 0.9445\n",
            "Epoch 13: val_loss improved from 0.29922 to 0.29692, saving model to files/model.h5\n",
            "125/125 [==============================] - 69s 556ms/step - loss: 0.1478 - accuracy: 0.9445 - val_loss: 0.2969 - val_accuracy: 0.8975 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9425\n",
            "Epoch 14: val_loss did not improve from 0.29692\n",
            "125/125 [==============================] - 66s 528ms/step - loss: 0.1582 - accuracy: 0.9425 - val_loss: 0.2981 - val_accuracy: 0.8925 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.9440\n",
            "Epoch 15: val_loss did not improve from 0.29692\n",
            "125/125 [==============================] - 65s 524ms/step - loss: 0.1510 - accuracy: 0.9440 - val_loss: 0.3014 - val_accuracy: 0.8925 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.9450\n",
            "Epoch 16: val_loss did not improve from 0.29692\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "125/125 [==============================] - 73s 589ms/step - loss: 0.1452 - accuracy: 0.9450 - val_loss: 0.2992 - val_accuracy: 0.8950 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.9545\n",
            "Epoch 17: val_loss did not improve from 0.29692\n",
            "125/125 [==============================] - 65s 520ms/step - loss: 0.1392 - accuracy: 0.9545 - val_loss: 0.2993 - val_accuracy: 0.8975 - lr: 1.0000e-06\n",
            "Epoch 18/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.9435\n",
            "Epoch 18: val_loss did not improve from 0.29692\n",
            "125/125 [==============================] - 68s 546ms/step - loss: 0.1522 - accuracy: 0.9435 - val_loss: 0.2995 - val_accuracy: 0.8975 - lr: 1.0000e-06\n",
            "Epoch 19/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1431 - accuracy: 0.9510\n",
            "Epoch 19: val_loss did not improve from 0.29692\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
            "125/125 [==============================] - 69s 555ms/step - loss: 0.1431 - accuracy: 0.9510 - val_loss: 0.2997 - val_accuracy: 0.8950 - lr: 1.0000e-06\n",
            "Epoch 20/50\n",
            "125/125 [==============================] - ETA: 0s - loss: 0.1477 - accuracy: 0.9480\n",
            "Epoch 20: val_loss did not improve from 0.29692\n",
            "125/125 [==============================] - 69s 551ms/step - loss: 0.1477 - accuracy: 0.9480 - val_loss: 0.2997 - val_accuracy: 0.8950 - lr: 1.0000e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivjva7rb0Say",
        "outputId": "3b061b25-e7f6-4145-d36b-805654d5581f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 121s 5s/step - loss: 0.1757 - accuracy: 0.9200\n",
            "Test accuracy: 0.9200000166893005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/pneumonia-dataset/files/model.h5')\n",
        "\n",
        "def processing(path):\n",
        "  img = cv2.imread(path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img, (w, h))\n",
        "  img = img / 255\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  return img\n"
      ],
      "metadata": {
        "id": "bD2o-_qqOXGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"/content/drive/MyDrive/pneumonia-dataset/test/NORMAL/test-normal_000.jpg\"\n",
        "x = model.predict(processing(test))\n",
        "x = np.squeeze(x, axis=0)\n",
        "x = 1 if x>.7 else 0\n",
        "x\n"
      ],
      "metadata": {
        "id": "K3qC-y0gQY51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698babba-ec1c-4440-ab83-13215ed5c455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fB_x5RSTuScE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}